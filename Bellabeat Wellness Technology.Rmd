---
title: "Bellabeat: Women Wellness Technology Company"
author: "Aziz Esfandiari"
date: "2022-12-30"
output: html_document
---


### Capstone project completed for the Google Data Analytics Professional Certificate
### *How Can a Wellness Technology Company Play It Smart?*

*Discover customer behavioral patterns to boost customer base*
 
## Background

Bellabeat was founded in 2013 to manufacture high-tech smart devices focused on women health. As a growing business, Bellabeat has been introducing new products. The Company's marketting team needs to devise smart strategies to attract more customers. To this end, I am going to analyze a public dataset, collected from FitBit customers, another manufacturer of health monitoring device. So, the main business task is "to analyze smart device data to gain insight into how consumers are using their smart devices". As a result, the report will include the following major deliverables:

1.	A clear statement of the business task 
2.	A description of all data sources used 
3.	Documentation of any cleaning or manipulation of data 
4.	A summary of your analysis 
5.	Supporting visualizations and key findings 
6.	Your top three recommendations based on your analysis

Since Bellabeat has introduced different health monitoring products and also offers subscription-based membership program, I take the latter (Bellabeat membership) as the focus of application of this analysis. The case study guide says: "Membership gives users 24/7 access to fully personalized guidance on nutrition, activity, sleep, health and beauty, and mindfulness based on their lifestyle and goals."

## 1.	Ask
This data analysis task is aimed at discovering how non-Bellabeat customers are using their smart devices. Analysis of the data will reveal consumer behavior and uncover meaningful patterns. This will produce insights and recommendations that would help the Bellabeat marketing team develop a promotional strategy to attract more potential customers. 

1.1.	Business Task: Analyze FitBit Fitness Tracker Data, a non-Bellabeat customer dataset, to determine customer behavioral patterns in using their smart devices.

1.2.	Key Stakeholders: Urška Sršen (Bellabeat’s co-founder and Chief Creative Officer), Sando Mur (Bellabeat’s co-founder and a key member of Bellabeat executive team), Bellabeat marketing analytics team.

## 2.	Prepare
The data is made public by [Mobius](https://www.kaggle.com/arashnic) and is accessible online at https://www.kaggle.com/datasets/arashnic/fitbit. This is a public, open-source dataset, containing personal fitness tracker data from thirty users who consented to the submission of their personal data. The data includes a period of two months in 2016.

The data is stored in CSV format and is organized by type of activity and several quantitative health indicators. There are a total of 18 tables but I will use a few related tables that best answer the questions about the business problem.

On the credibility of the data, there are a series of factors that impact its reliability, originality, and comprehensiveness.

1.	The sample size is small and no information is provided on the sampling technique So, it does not seem to be representative of the consumer population. Plus, it has plenty of missing data and is incomplete.

2.	It is not obtained through the primary data source, so, it is not original.

3.	It does not appear to be comprehensive since the existing variables (factors) do not answer some of the related questions to answer the business problem.

However, the data is generated by a large organization (FitBit) and the activity period could produce relatively reliable insights.

## 3.	Process
I have chosen R Programming Language for processing and analyzing the data because of its flexibility and visualization features.

**3.1. Load packages**

```{r}
library(tidyverse)
library(lubridate)
library(janitor)
library(readxl)
library(dplyr)
library(stringr)
library(here)
library(janitor)
library(skimr)
```

**3.2. Import tables:** I have reviewed and saved files in xlsx format. Some tables contain only a few unique records, some as few as 8. So, I import the data sets with unique ID numbers that match the sample size. The following tables contain 33 unique records, except for the daily_sleep which contain only 24. Since the "daily activity" table includes data from "daily calory", "daily intensity" and "daily steps" I need to import the first table only. The table "weight" would have given us useful insights if it contained data on all the sample participants. It only shows weight data for 8 participants. So, it is excluded from analysis.

```{r - import datasets}
daily_activity <- read_xlsx("/Users/aesfandiari/R/FitBit/excel_files/dailyActivity.xlsx")
daily_sleep <- read_xlsx("/Users/aesfandiari/R/FitBit/excel_files/sleepDay.xlsx")
hourly_step <- read_xlsx("/Users/aesfandiari/R/FitBit/excel_files/hourlySteps.xlsx")
hourly_intensity <- read_xlsx("/Users/aesfandiari/R/FitBit/excel_files/hourlyIntensities.xlsx")
hourly_calory <- read_xlsx("/Users/aesfandiari/R/FitBit/excel_files/hourlyCalories.xlsx")
```

**3.3. Check total and unique rows**

```{r}
nrow(daily_activity)
nrow(daily_sleep)
nrow(hourly_step)
nrow(hourly_intensity)
nrow(hourly_calory)
```

To confirm the number of unique rows, let's run n_distinct() fuction, while removing any null values.
```{r - show number of unique rows}
n_distinct(daily_activity$Id, na.rm = TRUE)
n_distinct(daily_sleep$Id, na.rm = TRUE)
n_distinct(hourly_step$Id, na.rm = TRUE)
n_distinct(hourly_intensity$Id, na.rm = TRUE)
n_distinct(hourly_calory$Id, na.rm = TRUE)
```

Let's use skim_without_charts() function to get a comprehensive summary of ur data frame. All variables appear to have the right data type.

**3.4. Summary of data**

```{r - summarize dataframe}
skim_without_charts(daily_activity)
skim_without_charts(daily_sleep)
skim_without_charts(hourly_calory)
skim_without_charts(hourly_intensity)
skim_without_charts(hourly_step)
```

The summary of data frames show that variables have the right data type and columns have meaningful names. So, we don't need to change the data type. However, I will use clean_names() function to make sure column names contain only characters, numbers and underscores.

**3.5. Clean column names**

```{r - clean names}
clean_names(daily_activity)
clean_names(daily_sleep)
clean_names(hourly_calory)
clean_names(hourly_intensity)
clean_names(hourly_step)
```

**3.6. Remove NAs**

The is.na() function shows that the data contains some null values. So, let's use na.omit() function to remove NAs.
```{r - remova null values, echo=FALSE}
na.omit(daily_activity)
na.omit(daily_sleep)
na.omit(hourly_calory)
na.omit(hourly_intensity)
na.omit(hourly_step)
```

**3.7. Join data frames**

At this stage, I have to join 'daily_activity' data frame with the 'daily_sleep' data frame by Id and also combine the three hourly measurement tables together. I will select the variables that we need for analysis to have clean and organized data frames.

```{r - join daily data frames}
merged_daily <- daily_activity %>% 
  left_join(daily_sleep) %>%
  select(Id, ActivityDate, steps = TotalSteps, distance = TotalDistance, VeryActiveDistance, ModeratelyActiveDistance, 
         LightActiveDistance, VeryActiveMinutes, ModeratelyActiveMinutes = FairlyActiveMinutes, LightlyActiveMinutes, Calories, TotalMinutesAsleep)
```

```{r - join hourly data frames}
merged_hourly <- left_join(hourly_step, hourly_calory, by = c("Id", "ActivityHour")) %>%
  select(Id, ActivityHour, TotalStep = StepTotal, Calories)
```

**3.8. Add Weekday Column**

```{r}
merged_daily <- mutate(merged_daily, WeekDay = wday(ActivityDate, week_start = 1, label = TRUE, abbr = FALSE))
merged_hourly <- mutate(merged_hourly, WeekDay = wday(ActivityHour, week_start = 1, label = TRUE, abbr = FALSE)) 
```


## 4. Analyze and Share
We have two final datasets: 'merged_daily' and 'merged_hourly'. We will explore them to find out what insights they can provide.

**4.1. Average steps, distance and calory**

let's begin the analysis with a summary of daily and hourly steps, distance and calory.

**a) Daily data**
```{r}
avg_daily <- merged_daily %>%
  summarize(avg_step = mean(steps), avg_distance = mean(distance), avg_calory = mean(Calories)) %>%
  arrange(-avg_distance)
```
```{r - print summary_daily, echo=FALSE}
avg_daily
```
A more detailed overview of the above variables look like this:
```{r}
summary_daily <- merged_daily %>%
  group_by(Id) %>% 
  summarize(min_steps = min(steps), max_steps = max(steps), avg_step = mean(steps), mean_distance = min(distance), 
  max_distance = max(distance), avg_distance = mean(distance), min_calory = min(Calories), max_calory = max(Calories), 
  avg_calory = mean(Calories)) %>% 
  arrange(-avg_distance)
```
```{r echo=FALSE}
summary_daily
```

**b) Hourly data**
```{r}
summary_hourly <- merged_hourly %>% 
  group_by(Id) %>% 
  summarise(max_step = max(TotalStep), avg_step = mean(TotalStep), max_calory = max(Calories), avg_calory = mean(Calories)) %>% 
  arrange(-avg_step)
```
```{r}
summary_hourly
```

**4.2. Correlation between steps and calory**

***Correltion Coefficient***
```{r - correlation between steps and distance and calory, echo=FALSE}
cor(merged_daily$steps, merged_daily$Calories)
```

```{r}
merged_daily %>%
  ggplot(aes(x = steps, y = Calories)) +
  geom_point() +
  geom_smooth() +
  labs(title = "steps vs calories")
```

**4.3. Steps/Calory/Sleep Per Weekday**

```{r - steps vs calory by weekday}
merged_daily %>%
  ggplot(aes(x = steps, y = Calories,)) +
  geom_point() +
  geom_smooth() +
  labs(title = "steps vs calories") +
  facet_wrap(~WeekDay)
```

**4.4. Correlation between distance and calory**

***Correltion Coefficient***
```{r echo=FALSE}
cor(merged_daily$distance, merged_daily$Calories)
```
  
```{r}
merged_daily %>% 
  ggplot(aes(x = distance, y = Calories)) +
  geom_line() +
  geom_smooth() +
  labs(title = "distance vs calory")
```

```{r - distance vs calory by weekday}
merged_daily %>% 
  ggplot(aes(x = distance, y = Calories)) +
  geom_line() +
  geom_smooth() +
  labs(title = "distance vs calory") +
  facet_wrap(~WeekDay)
```

**4.5 steps, calory, sleep hour per weekday**

```{r}
daily_average <- merged_daily %>% 
  group_by(WeekDay) %>% 
  summarize(avg_step = mean(steps), avg_calory = mean(Calories), avg_sleep_hr = mean(TotalMinutesAsleep/60, na.rm = TRUE))
```
```{r}
daily_average
```


```{r}
options(scipen = 999)
ggplot(data = merged_daily, aes(x = WeekDay, y = steps, fill = WeekDay)) +
  geom_bar(stat = "identity") +
  labs(title = "steps per weekday")
```

```{r}
options(scipen = 999)
ggplot(data = merged_daily, aes(x = WeekDay, y = Calories, fill = WeekDay)) +
  geom_bar(stat = "identity") +
  labs(title = "Calory burnt per weekday")
```

```{r}
options(scipen = 999)
ggplot(data = merged_daily, aes(x = WeekDay, y = TotalMinutesAsleep/60, fill = WeekDay)) +
  geom_bar(stat = "identity") +
  labs(title = "sleep hours per weekday")
```

**4.6 Walking Hours**

Now, let's find out in what time of the day most users go walking. To this end, let's create a time column and extract hours from 'ActivityHour' Column. 

```{r}
merged_hourly$time <- format(as.POSIXct(merged_hourly$ActivityHour), format = "%H:%M:%S")
```

```{r}
ggplot(data = merged_hourly) +
  geom_bar(stat = "identity") +
  aes(x = time, y = TotalStep, fill = time) +
  labs(title = "Walking Hours") +
  theme(axis.text.x = element_text(angle = 90))
```

**4.7. Average Active minutes per type**
```{r}
type_active_minutes <- merged_daily %>% 
  group_by(WeekDay) %>% 
  summarize(avg_very_active = mean(VeryActiveMinutes), avg_moderate_active = mean(ModeratelyActiveMinutes), avg_light_active = mean(LightlyActiveMinutes))
```
```{r}
print(type_active_minutes)
```


## 5.	Act (Recommendation)
Based on the insights pulled from the data, these are the three top recommendations for the Bellabeat subscription service:

1. On average, the participants walked more than 8000 steps, a distance close to 6 miles and burnt 2,329 calories per day. Tuesday, Wednesday and Thursday are the most active days of the week; users are less active during weekends. Bellabeat can provide the weekend notification system to encourage users get more active during weekends.
2. The highest activity level of users is seen between 5 pm to 7 pm, followed by 12 pm to 2 pm. As expected, 11 pm to 6 am is the least active period of the day. Bellabeat subscription service can customize health monitoring features to reflect the most and least active hours of the day so that users can adjust their diet and other health habits accordingly.
3. Correlation between distance and burning calory is stronger (0.55) than that of steps and burning calory (0.45). So, The distance walked is a better indicator to see the level of calory burnt than the number of steps because most steps take are in the lightly active hours which do not contribute much to burning calory. So, adding a feature to highlight the distance walked and calory burnt would give users a more accurate insight.


